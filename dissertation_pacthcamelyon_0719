import h5py
import torch
import pandas as pd
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms.functional as F
from torchvision import transforms, models
from PIL import Image
import random
from skimage.color import rgb2gray
from skimage import img_as_float
import numpy as np
import torch.optim as optim
import time
import copy
import torch.nn as nn
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, precision_score, recall_score
import cv2
from torch.optim.lr_scheduler import StepLR
import torchprofile
from thop import profile



def set_seed(seed):
    # Set the random seed for Python's built-in random module
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)

    #Set CuDNN to use a deterministic algorithm to ensure consistent results every time
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# Setting the random seed
set_seed(2024)



# 数据增强
def apply_transforms(image):
    if random.random() > 0.5:
        image = F.hflip(image)
    
    angles = [90, 180, 270]
    angle = random.choice(angles)
    image = F.rotate(image, angle)

    image = transforms.ColorJitter(brightness=0.4, contrast=0.5, saturation=0.3, hue=0.1)(image)
    #image = transforms.ColorJitter(brightness=0.25, contrast=0.75, saturation=0.25, hue=0.04)(image)
    image_tensor = F.to_tensor(image)
    image_tensor = F.normalize(image_tensor, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    
    return image_tensor

# 组织分割
def tissue_segmentation(image):
    image[(image == 0).all(axis=-1)] = [255, 255, 255]
    gray_image = rgb2gray(image)
    gray_image = img_as_float(gray_image)
    tissue_mask = gray_image <= 0.8
    return tissue_mask

# 自定义数据集
class CamelyonDataset(Dataset):
    def __init__(self, data_file, labels_file, meta_file, transform=None, test=False):
        self.data_file = data_file
        self.labels = self.load_h5_labels(labels_file)
        self.meta = self.load_csv(meta_file)
        self.transform = transform
        self.test = test
        with h5py.File(data_file, 'r') as file:
            self.data_length = file['x'].shape[0]

    def load_h5_labels(self, file_path):
        with h5py.File(file_path, 'r') as file:
            labels = file['y'][:].astype(np.float32)
            return torch.tensor(labels).view(-1, 1) 

    def load_csv(self, file_path):
        return pd.read_csv(file_path)

    def __len__(self):
        return self.data_length

    def __getitem__(self, idx):
        with h5py.File(self.data_file, 'r') as file:
            image = file['x'][idx].astype('uint8')
        tissue_mask = tissue_segmentation(image)
        image[tissue_mask == False] = [255, 255, 255]
        image = Image.fromarray(image, 'RGB')
        if self.test:
            image_tensor = F.to_tensor(image)
            image_tensor = F.normalize(image_tensor, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        else:
            image_tensor = apply_transforms(image)
        label = self.labels[idx]
        return transforms.ToTensor()(image), image_tensor, label


class MobileNetV3Classifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = models.mobilenet_v3_large(weights='IMAGENET1K_V1')
        self.backbone.features[0][0] = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)  # Adjust first conv layer if necessary
        num_ftrs = self.backbone.classifier[3].in_features
        self.backbone.classifier[3] = nn.Sequential(
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(512, 1),
            nn.Sigmoid()  # 添加 Sigmoid 层
        )

    def forward(self, x):
        return self.backbone(x)



class ShuffleNetV2Classifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = models.shufflenet_v2_x1_0(weights='IMAGENET1K_V1')
        self.backbone.conv1[0] = nn.Conv2d(3, 24, kernel_size=3, stride=2, padding=1, bias=False)  # Adjust first conv layer if necessary
        num_ftrs = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(512, 1),
            nn.Sigmoid()  # 添加 Sigmoid 层
        )

    def forward(self, x):
        return self.backbone(x)


class SqueezeNetClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = models.squeezenet1_0(weights='IMAGENET1K_V1')
        self.backbone.features[0] = nn.Conv2d(3, 96, kernel_size=3, stride=2, padding=1, bias=False)  # Adjust first conv layer if necessary
        self.backbone.classifier[1] = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1)),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        )
        self.backbone = nn.Sequential(self.backbone, nn.Sigmoid())

    def forward(self, x):
        x = self.backbone(x)
        return x.view(-1, 1)


class ResNetClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = models.resnet18(weights='IMAGENET1K_V1')
        self.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)  # Adjust first conv layer if necessary
        self.backbone.maxpool = nn.Identity()  # Remove max pooling layer to handle smaller input
        num_ftrs = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(512, 1),
            nn.Sigmoid()  # 添加 Sigmoid 层
        )
        
    def forward(self, x):
        return self.backbone(x)


class EfficientNetClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = models.efficientnet_b0(weights='IMAGENET1K_V1')
        self.backbone.features[0][0] = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)  # Adjust first conv layer if necessary
        num_ftrs = self.backbone.classifier[1].in_features
        self.backbone.classifier = nn.Sequential(
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(512, 1)
        )
        self.backbone = nn.Sequential(self.backbone, nn.Sigmoid())

    def forward(self, x):
        return self.backbone(x)



# 训练函数
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model.to(device)

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    best_auc = 0.0
    since = time.time()

    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []

    for epoch in range(num_epochs):
        print('-' * 20)
        print(f'Epoch {epoch}/{num_epochs - 1}')
        

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  
                dataloader = train_loader
            else:
                model.eval()   
                dataloader = val_loader

            running_loss = 0.0
            running_corrects = 0
            all_labels = []
            all_outputs = []

            for inputs, _, labels in dataloader:
                inputs = inputs.to(device)
                labels = labels.to(device)
                
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    preds = outputs > 0.5

                    if phase == 'train':
                        optimizer.zero_grad()
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
                all_labels.extend(labels.cpu().numpy())
                all_outputs.extend(outputs.detach().cpu().numpy())

            epoch_loss = running_loss / len(dataloader.dataset)
            epoch_acc = running_corrects.double() / len(dataloader.dataset)
            epoch_auc = roc_auc_score(all_labels, all_outputs)

            if phase == 'train':
                train_losses.append(epoch_loss)
                train_accuracies.append(epoch_acc)
                scheduler.step()  # 在训练阶段结束时调用调度器的step方法
            else:
                val_losses.append(epoch_loss)
                val_accuracies.append(epoch_acc)
                early_stopping(epoch_loss, model)
                if early_stopping.early_stop:
                    print("Early stopping")
                    model.load_state_dict(best_model_wts)
                    return model, best_acc, best_auc, train_losses, val_losses, train_accuracies, val_accuracies


            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} AUC: {epoch_auc:.4f}')

            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_auc = epoch_auc
                best_model_wts = copy.deepcopy(model.state_dict())

    time_elapsed = time.time() - since
    
    print(f'\n Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val Acc: {best_acc:.4f} AUC: {best_auc:.4f}')

    model.load_state_dict(best_model_wts)
    
    return model, best_acc, best_auc, train_losses, val_losses, train_accuracies, val_accuracies

# 测试函数
def test_model(model, test_loader, criterion):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model.to(device)

    model.eval()
    running_loss = 0.0
    running_corrects = 0
    all_labels = []
    all_outputs = []

    with torch.no_grad():
        for inputs, _, labels in test_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            preds = outputs > 0.5

            running_loss
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)
            all_labels.extend(labels.cpu().numpy())
            all_outputs.extend(outputs.detach().cpu().numpy())

    test_loss = running_loss / len(test_loader.dataset)
    test_acc = running_corrects.double() / len(test_loader.dataset)
    test_auc = roc_auc_score(all_labels, all_outputs)
    test_precision = precision_score(all_labels, np.round(all_outputs))
    test_recall = recall_score(all_labels, np.round(all_outputs))

    print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f} AUC: {test_auc:.4f} Precision: {test_precision:.4f} Recall: {test_recall:.4f}')
    return test_loss, test_acc, test_auc, test_precision, test_recall

# 计算验证集运行时间的函数
def validation_runtime(model, val_loader):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model.to(device)

    model.eval()
    start_time = time.time()

    with torch.no_grad():
        for inputs, _, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = model(inputs)

    end_time = time.time()
    runtime = end_time - start_time
    return runtime


# 保存原始和增强后的图像
def save_display_images(original_images, transformed_images, filename):
    fig, axes = plt.subplots(2, len(original_images), figsize=(15, 5))
    for i in range(len(original_images)):
        axes[0, i].imshow(original_images[i])
        axes[0, i].set_title('Original Image', fontsize=10)
        axes[0, i].axis('off')
        
        axes[1, i].imshow(transformed_images[i].permute(1, 2, 0))
        axes[1, i].set_title('Transformed Image', fontsize=10)
        axes[1, i].axis('off')
    plt.tight_layout()
    plt.savefig(filename)
    plt.close()

class EarlyStopping:
    def __init__(self, patience=7, delta=0):
        self.patience = patience
        self.delta = delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss + self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

def print_model_summary(model, indent=0):
    for name, module in model.named_children():
        print(' ' * indent + f"{name}: {module.__class__.__name__}")
        print_model_summary(module, indent + 2)

# 检查并转换张量
def to_cpu_numpy(tensor):
    if torch.is_tensor(tensor):
        return tensor.cpu().numpy()
    return tensor

# 定义计算FLOPs的函数
def calculate_flops(model, input_size=(3, 96, 96)):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model.to(device)
    
    inputs = torch.randn(1, *input_size).to(device)
    flops, params = profile(model, inputs=(inputs,))
    
    return flops, params

# 主程序
if __name__ == '__main__':
    #Dataset loading and preparation
    train_dataset = CamelyonDataset('camedata/camelyonpatch_level_2_split_train_x_subset.h5',
                                    'camedata/camelyonpatch_level_2_split_train_y_subset.h5',
                                    'camedata/camelyonpatch_level_2_split_train_meta.csv',
                                    transform=apply_transforms)

    val_dataset = CamelyonDataset('camedata/camelyonpatch_level_2_split_valid_x_subset.h5',
                                  'camedata/camelyonpatch_level_2_split_valid_y_subset.h5',
                                  'camedata/camelyonpatch_level_2_split_valid_meta.csv',
                                  transform=apply_transforms)

    test_dataset = CamelyonDataset('camedata/camelyonpatch_level_2_split_test_x_subset.h5',
                                   'camedata/camelyonpatch_level_2_split_test_y_subset.h5',
                                   'camedata/camelyonpatch_level_2_split_test_meta.csv',
                                   test=True)
    #Load the training, validation, and test datasets and create data loaders for each.
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)
    
    #Using binary cross entropy loss function
    criterion = nn.BCELoss()
    
    #Define a model dictionary to store different models
    models_dict = {
        'MobileNetV3': MobileNetV3Classifier(),
        'ShuffleNetV2': ShuffleNetV2Classifier(),
        'SqueezeNet': SqueezeNetClassifier(),
        'EfficientNet': EfficientNetClassifier(),
        'ResNet18': ResNetClassifier()
    }
    
    # 定义model_names变量
    model_names = list(models_dict.keys())


    # 打印各个模型的简化结构
    for model_name, model in models_dict.items():
        print(f"\n{model_name} structure:\n")
        print_model_summary(model)

    results = {}
    heatmaps = {}
    train_losses_dict = {}
    val_losses_dict = {}
    train_accuracies_dict = {}
    val_accuracies_dict = {}
    val_runtimes = {}
    flops_dict = {}

    # 随机选择几张图像并展示
    sample_indices = random.sample(range(len(train_dataset)), 5)
    original_images = []
    transformed_images = []

    for idx in sample_indices:
        original_image, transformed_image, _ = train_dataset[idx]
        original_images.append(original_image.permute(1, 2, 0).numpy())
        transformed_images.append(transformed_image)
    
    save_display_images(original_images, transformed_images, 'original_and_transformed_images.png')

    #Model training and evaluation
    for model_name, model in models_dict.items():
        print(f'\n[Training {model_name} model...]\n')
        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)  # Adding L2 regularization
        scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Reduce LR by a factor of 0.1 every 10 epochs
        criterion = nn.BCELoss()
        early_stopping = EarlyStopping(patience=10, delta=0.01)

        # 对每个模型进行训练，记录最佳准确率和AUC，以及训练和验证集的损失和准确率。
        model, best_acc, best_auc, train_losses, val_losses, train_accuracies, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2)
        val_runtime = validation_runtime(model, val_loader)
        
        #Evaluate on the test set and record the test loss, accuracy, AUC, precision, and recall.
        test_loss, test_acc, test_auc, test_precision, test_recall = test_model(model, test_loader, criterion)
        
        #计算模型参数总数和每张图像的推理时间
        total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        inference_time = validation_runtime(model, test_loader) / len(test_loader.dataset)
        
        # 计算模型的FLOPs
        flops, params = calculate_flops(model)
        flops_dict[model_name] = flops

        results[model_name] = {
            'Test Loss': test_loss,
            'Test Accuracy': test_acc.item(),
            'Test AUC': test_auc,
            'Precision': test_precision,
            'Recall': test_recall,
            'Total Parameters': total_params,
            'Inference Time per Image': inference_time,
            'FLOPs': flops
        }

        val_runtimes[model_name] = val_runtime

        train_losses_dict[model_name] = train_losses
        val_losses_dict[model_name] = val_losses
        train_accuracies_dict[model_name] = train_accuracies
        val_accuracies_dict[model_name] = val_accuracies

    # 结果存储
    # 打印每个模型的结果
    for model_name, metrics in results.items():
        print(f'\n{model_name} Results:')
        for metric_name, value in metrics.items():
            print(f'{metric_name}: {value}')
    #提取各项指标，准备绘图
    model_names = list(results.keys())
    accuracies = [results[model]['Test Accuracy'] for model in model_names]
    aucs = [results[model]['Test AUC'] for model in model_names]
    precisions = [results[model]['Precision'] for model in model_names]
    recalls = [results[model]['Recall'] for model in model_names]
    params = [results[model]['Total Parameters'] for model in model_names]
    inf_times = [results[model]['Inference Time per Image'] for model in model_names]
    flops_values = [results[model]['FLOPs'] for model in model_names]
    val_runtime_values = [val_runtimes[model] for model in model_names]

    # 绘制训练和验证精度曲线
    for model_name in model_names:
        train_accuracies = [to_cpu_numpy(acc) for acc in train_accuracies_dict[model_name]]
        val_accuracies = [to_cpu_numpy(acc) for acc in val_accuracies_dict[model_name]]
        
        plt.figure()
        plt.plot(range(len(train_accuracies)), train_accuracies, label='Training Accuracy')
        plt.plot(range(len(val_accuracies)), val_accuracies, label='Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.title(f'{model_name} Training and Validation Accuracy')
        plt.legend()
        plt.savefig(f'{model_name}_accuracy_curve.png')
        plt.close()

    # 绘制训练和验证损失曲线
    for model_name in model_names:
        train_losses = [to_cpu_numpy(loss) for loss in train_losses_dict[model_name]]
        val_losses = [to_cpu_numpy(loss) for loss in val_losses_dict[model_name]]
        
        plt.figure()
        plt.plot(range(len(train_losses)), train_losses, label='Training Loss')
        plt.plot(range(len(val_losses)), val_losses, label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title(f'{model_name} Training and Validation Loss')
        plt.legend()
        plt.savefig(f'{model_name}_loss_curve.png')
        plt.close()

    # Plotting other metrics
    # 图表1: Model Accuracy and Inference Time Comparison
    fig, ax1 = plt.subplots()

    color = 'tab:blue'
    ax1.set_xlabel('Model')
    ax1.set_ylabel('Accuracy', color=color)
    ax1.bar(model_names, accuracies, color=color, alpha=0.6, label='Accuracy')
    ax1.tick_params(axis='y', labelcolor=color)

    ax2 = ax1.twinx()
    color = 'tab:red'
    ax2.set_ylabel('Inference Time (s)', color=color)
    ax2.plot(model_names, inf_times, color=color, marker='o', label='Inference Time')
    ax2.tick_params(axis='y', labelcolor=color)

    fig.tight_layout(rect=[0, 0, 1, 0.95])
    plt.title('Model Accuracy and Inference Time Comparison')
    plt.savefig('model_accuracy_inference_time_comparison.png')

    # 图表2: Validation Runtime Comparison
    fig, ax3 = plt.subplots()

    color = 'tab:green'
    ax3.set_xlabel('Model')
    ax3.set_ylabel('Validation Runtime (s)', color=color)
    ax3.bar(model_names, val_runtime_values, color=color, alpha=0.6, label='Validation Runtime')
    ax3.tick_params(axis='y', labelcolor=color)

    fig.tight_layout(rect=[0, 0, 1, 0.95])
    plt.title('Validation Runtime Comparison')
    plt.savefig('validation_runtime_comparison.png')

    # 图表3: Model Parameters Comparison
    fig, ax4 = plt.subplots()

    color = 'tab:purple'
    ax4.set_xlabel('Model')
    ax4.set_ylabel('Total Parameters', color=color)
    ax4.bar(model_names, params, color=color, alpha=0.6, label='Total Parameters')
    ax4.tick_params(axis='y', labelcolor=color)

    fig.tight_layout(rect=[0, 0, 1, 0.95])
    plt.title('Model Parameters Comparison')
    plt.savefig('model_parameters_comparison.png')

    # 图表4: Model Inference Time Comparison
    fig, ax5 = plt.subplots()

    color = 'tab:orange'
    ax5.set_xlabel('Model')
    ax5.set_ylabel('Inference Time (s)', color=color)
    ax5.bar(model_names, inf_times, color=color, alpha=0.6, label='Inference Time')
    ax5.tick_params(axis='y', labelcolor=color)

    fig.tight_layout(rect=[0, 0, 1, 0.95])
    plt.title('Model Inference Time Comparison')
    plt.savefig('model_inference_time_comparison.png')

    # 图表5: Model Precision Comparison
    fig, ax6 = plt.subplots()

    color = 'tab:brown'
    ax6.set_xlabel('Model')
    ax6.set_ylabel('Precision', color=color)
    ax6.bar(model_names, precisions, color=color, alpha=0.6, label='Precision')
    ax6.tick_params(axis='y', labelcolor=color)
    
    fig.tight_layout(rect=[0, 0, 1, 0.95])
    plt.title('Model Precision Comparison')
    plt.savefig('model_precision_comparison.png')

    # 图表6: Model Recall Comparison
    fig, ax7 = plt.subplots()

    color = 'tab:cyan'
    ax7.set_xlabel('Model')
    ax7.set_ylabel('Recall', color=color)
    ax7.bar(model_names, recalls, color=color, alpha=0.6, label='Recall')
    ax7.tick_params(axis='y', labelcolor=color)

    fig.tight_layout(rect=[0, 0, 1, 0.95])
    plt.title('Model Recall Comparison')
    plt.savefig('model_recall_comparison.png')

    # 图表7: Model FLOPs Comparison
    fig, ax8 = plt.subplots()

    color = 'tab:pink'
    ax8.set_xlabel('Model')
    ax8.set_ylabel('FLOPs', color=color)
    ax8.bar(model_names, flops_values, color=color, alpha=0.6, label='FLOPs')
    ax8.tick_params(axis='y', labelcolor=color)

    fig.tight_layout(rect=[0, 0, 1, 0.95])
    plt.title('Model FLOPs Comparison')
    plt.savefig('model_flops_comparison.png')

    print("Training and evaluation completed, and plots are saved.")
